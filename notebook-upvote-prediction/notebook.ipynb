{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f33c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import re\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2267292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURATION & DATA LOADING\n",
    "# ==========================================\n",
    "TRAIN_PATH = \"data/public/train.csv\"\n",
    "TEST_PATH = \"data/public/test.csv\"\n",
    "SUBMISSION_PATH = \"data/public/submission.csv\"\n",
    "\n",
    "# Leakage: Metrics accumulated AFTER publication\n",
    "LEAKAGE_COLS = [\n",
    "    \"fork_count\",\n",
    "    \"views\",\n",
    "    \"downloads\",\n",
    "    \"comments_count\",\n",
    "    \"notebook_usage\",\n",
    "    \"medal\",\n",
    "    \"is_featured\",\n",
    "    \"is_trending\",\n",
    "    \"engagement_rate\",\n",
    "    \"virality_score\",\n",
    "    \"quality_score\",\n",
    "]\n",
    "\n",
    "# Irrelevant: All-null or ID metadata\n",
    "IRRELEVANT_COLS = [\n",
    "    \"usability_score\",\n",
    "    \"file_format\",\n",
    "    \"column_count\",\n",
    "    \"row_count\",\n",
    "    \"license_type\",\n",
    "    \"content_type\",\n",
    "    \"author_username\",\n",
    "]\n",
    "\n",
    "\n",
    "def load_and_filter(path, is_train=True):\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {path}\")\n",
    "        return None\n",
    "\n",
    "    # Filter for notebooks only (as per problem description)\n",
    "    if \"content_type\" in df.columns:\n",
    "        df = df[df[\"content_type\"] == \"notebook\"].copy()\n",
    "\n",
    "    # Drop prohibited columns\n",
    "    cols_to_drop = [c for c in LEAKAGE_COLS + IRRELEVANT_COLS if c in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load Data\n",
    "print(\"Loading data...\")\n",
    "train_df = load_and_filter(TRAIN_PATH, is_train=True)\n",
    "test_df = load_and_filter(TEST_PATH, is_train=False)\n",
    "\n",
    "if train_df is None or test_df is None:\n",
    "    exit()\n",
    "\n",
    "# Target Transformation: log(1 + y)\n",
    "# This matches the evaluation metric: MAE of logs\n",
    "y = np.log1p(train_df[\"upvotes\"])\n",
    "X = train_df.drop(columns=[\"upvotes\"])\n",
    "X_test = test_df.copy()\n",
    "\n",
    "# Store IDs for submission\n",
    "test_ids = X_test[\"content_id\"]\n",
    "X = X.drop(columns=[\"content_id\"])\n",
    "X_test = X_test.drop(columns=[\"content_id\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c84de",
   "metadata": {},
   "source": [
    "# 2. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee87b1c4",
   "metadata": {},
   "source": [
    "## A. Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430c093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text...\n",
      "Processing tags...\n"
     ]
    }
   ],
   "source": [
    "def process_dates(df):\n",
    "    for col in [\"created_date\", \"last_updated\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "            # Feature 1: Numerical Timestamp\n",
    "            df[f\"{col}_ts\"] = df[col].astype(np.int64) // 10**9 // 86400\n",
    "\n",
    "            # Feature 2: Day of Week\n",
    "            df[f\"{col}_dow\"] = df[col].dt.dayofweek\n",
    "            \n",
    "            df = df.drop(columns=[col])\n",
    "    return df\n",
    "\n",
    "X = process_dates(X)\n",
    "X_test = process_dates(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9268e",
   "metadata": {},
   "source": [
    "## B. Interaction Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905126e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"days_since_creation\" in X.columns and \"update_count\" in X.columns:\n",
    "    X[\"update_freq\"] = X[\"days_since_creation\"] / (X[\"update_count\"] + 1)\n",
    "    X_test[\"update_freq\"] = X_test[\"days_since_creation\"] / (X_test[\"update_count\"] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfac0d8",
   "metadata": {},
   "source": [
    "## C. Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=100, stop_words=\"english\")\n",
    "title_train = tfidf.fit_transform(X[\"title\"].fillna(\"\"))\n",
    "title_test = tfidf.transform(X_test[\"title\"].fillna(\"\"))\n",
    "\n",
    "title_cols = [f\"title_{i}\" for i in range(title_train.shape[1])]\n",
    "title_train_df = pd.DataFrame(title_train.toarray(), columns=title_cols, index=X.index)\n",
    "title_test_df = pd.DataFrame(title_test.toarray(), columns=title_cols, index=X_test.index)\n",
    "\n",
    "X = X.drop(columns=[\"title\"])\n",
    "X_test = X_test.drop(columns=[\"title\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c011b",
   "metadata": {},
   "source": [
    "## D. Multi-Label Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multilabel(train, test, col_name, top_n=30):\n",
    "    # 1. Split strings by pipe '|'\n",
    "    train_split = train[col_name].fillna(\"\").astype(str).apply(lambda x: x.split(\"|\") if x else [])\n",
    "    test_split = test[col_name].fillna(\"\").astype(str).apply(lambda x: x.split(\"|\") if x else [])\n",
    "\n",
    "    # 2. Binarize\n",
    "    mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "    mlb.fit(train_split)\n",
    "\n",
    "    # Transform\n",
    "    train_enc = pd.DataFrame(\n",
    "        mlb.transform(train_split),\n",
    "        columns=[f\"{col_name}_{c}\" for c in mlb.classes_],\n",
    "        index=train.index,\n",
    "    )\n",
    "    test_enc = pd.DataFrame(\n",
    "        mlb.transform(test_split),\n",
    "        columns=[f\"{col_name}_{c}\" for c in mlb.classes_],\n",
    "        index=test.index,\n",
    "    )\n",
    "\n",
    "    # 3. Keep only Top N most frequent to reduce noise/memory\n",
    "    if train_enc.shape[1] > top_n:\n",
    "        top_cols = train_enc.sum().sort_values(ascending=False).head(top_n).index\n",
    "        return train_enc[top_cols], test_enc[top_cols]\n",
    "\n",
    "    return train_enc, test_enc\n",
    "\n",
    "\n",
    "print(\"Processing tags...\")\n",
    "# Libraries\n",
    "libs_train, libs_test = process_multilabel(X, X_test, \"libraries_used\", top_n=50)\n",
    "X = X.drop(columns=[\"libraries_used\"])\n",
    "X_test = X_test.drop(columns=[\"libraries_used\"])\n",
    "\n",
    "# Topics\n",
    "topics_train, topics_test = process_multilabel(X, X_test, \"all_topics\", top_n=30)\n",
    "X = X.drop(columns=[\"all_topics\"])\n",
    "X_test = X_test.drop(columns=[\"all_topics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d2e166",
   "metadata": {},
   "source": [
    "## E. Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier_mapping = {\"Novice\": 0, \"Contributor\": 1, \"Expert\": 2, \"Master\": 3, \"Grandmaster\": 4}\n",
    "X[\"author_tier\"] = X[\"author_tier\"].map(tier_mapping)\n",
    "X_test[\"author_tier\"] = X_test[\"author_tier\"].map(tier_mapping)\n",
    "cat_cols = [\"programming_language\", \"primary_topic\"]\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "X[cat_cols] = X[cat_cols].fillna(\"Missing\")\n",
    "X_test[cat_cols] = X_test[cat_cols].fillna(\"Missing\")\n",
    "\n",
    "ohe_train = pd.DataFrame(\n",
    "    ohe.fit_transform(X[cat_cols]), columns=ohe.get_feature_names_out(), index=X.index\n",
    ")\n",
    "ohe_test = pd.DataFrame(\n",
    "    ohe.transform(X_test[cat_cols]), columns=ohe.get_feature_names_out(), index=X_test.index\n",
    ")\n",
    "\n",
    "X = X.drop(columns=cat_cols)\n",
    "X_test = X_test.drop(columns=cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24156a4",
   "metadata": {},
   "source": [
    "## F. Numerical Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fecb5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_num = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
    "X_test_num = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "X_final = pd.concat([X_num, title_train_df, libs_train, topics_train, ohe_train], axis=1)\n",
    "X_test_final = pd.concat([X_test_num, title_test_df, libs_test, topics_test, ohe_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc66ce1",
   "metadata": {},
   "source": [
    "# 3. MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50165a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Log-MAE: 0.9701\n",
      "Best Params: {'subsample': 1.0, 'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "xgb_reg = xgb.XGBRegressor(\n",
    "    objective=\"reg:absoluteerror\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"subsample\": [0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb_reg,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "search.fit(X_final, y)\n",
    "\n",
    "print(f\"Best Log-MAE: {-search.best_score_:.4f}\")\n",
    "print(f\"Best Params: {search.best_params_}\")\n",
    "\n",
    "best_model = search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a94b1",
   "metadata": {},
   "source": [
    "# 4. PREDICTION & SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63135a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to data/public/submission.csv\n"
     ]
    }
   ],
   "source": [
    "log_preds = best_model.predict(X_test_final)\n",
    "\n",
    "preds = np.expm1(log_preds)\n",
    "preds = np.maximum(preds, 0)\n",
    "\n",
    "submission = pd.DataFrame({\"content_id\": test_ids, \"upvotes\": preds})\n",
    "\n",
    "submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "print(f\"Submission saved to {SUBMISSION_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shipd-eris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
